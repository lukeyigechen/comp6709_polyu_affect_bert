# Detecting emotions using fine-tuned BERT-based models

The repository contains the script that fine-tunes pre-trained BERT variants using the SemEval-2018 Task 1 (Affect in Tweets) dataset. It serves as part of the final project of Group 30 (Hoi-Yin, Yongcheng, Yige, Shuyuan) for COMP6709 (sp23) at Hong Kong Polytechnic University. The aim of fine-tuning BERT models is to detect emotions in user's inputs which could potentially assist generative language models to produce improved responses. 

The notebook is suitable for Colab uses (assuming the datasets are stored in the user's drive when mounting). Alternatively, please place the V-oc datasets from SemEval-2018 Task 1 into the working directory. 
